{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your data directory\n",
    "data_dir = r'f1_wc'\n",
    "race_events_dir = r'f1_re'\n",
    "\n",
    "# Load data\n",
    "lap_times = pd.read_csv(os.path.join(data_dir, 'lap_times.csv'))\n",
    "pit_stops = pd.read_csv(os.path.join(data_dir, 'pit_stops.csv'))\n",
    "results = pd.read_csv(os.path.join(data_dir, 'results.csv'))\n",
    "circuits = pd.read_csv(os.path.join(data_dir, 'circuits.csv'))\n",
    "safety_cars = pd.read_csv(os.path.join(race_events_dir, 'safety_cars.csv'))\n",
    "races = pd.read_csv(os.path.join(data_dir, 'races.csv'))\n",
    "drivers = pd.read_csv(os.path.join(data_dir, 'drivers.csv'))\n",
    "wiki_data = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_Formula_One_circuits\")[2]\n",
    "\n",
    "# Drop unnecessary column in the Wiki dataset\n",
    "wiki_data.drop('Map', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the lap times and pit stops data\n",
    "lap_times = lap_times.sort_values(['raceId', 'driverId', 'lap'])\n",
    "pit_stops = pit_stops.sort_values(['raceId', 'driverId', 'stop'])\n",
    "\n",
    "# Merge lap_times and pit_stops into merge1\n",
    "merge1 = pd.merge(lap_times, pit_stops, \n",
    "                  left_on=['raceId', 'driverId', 'lap'], \n",
    "                  right_on=['raceId', 'driverId', 'lap'], \n",
    "                  how='left',\n",
    "                  suffixes=('_lap', '_pit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         2\n",
       "2         3\n",
       "3         4\n",
       "4         5\n",
       "         ..\n",
       "25835    16\n",
       "25836    17\n",
       "25837    18\n",
       "25838    19\n",
       "25839    -1\n",
       "Name: position, Length: 25840, dtype: int32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace missing position values in results and convert position to integer\n",
    "results['position'].replace({'\\\\N':-1}, inplace=True)\n",
    "results['position'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge merge1 and results into merge2\n",
    "merge2 = pd.merge(merge1, results, \n",
    "                  left_on=['raceId', 'driverId', 'lap'], \n",
    "                  right_on=['raceId', 'driverId', 'laps'], \n",
    "                  how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Race into Year and Race in safety_cars dataset\n",
    "safety_cars['Race'] = safety_cars['Race'].str.strip()\n",
    "safety_cars[['Year', 'Race']] = safety_cars['Race'].str.split(' ', 1, expand=True)\n",
    "\n",
    "def split_years(season):\n",
    "    years = []\n",
    "    if ',' in season:  # case of comma-separated years\n",
    "        elements = season.split(', ')\n",
    "        for el in elements:\n",
    "            el = re.sub(r'\\[.*\\]', '', el)  # strip off suffixes\n",
    "            if '–' in el:  # case of a range within comma-separated years\n",
    "                start, end = map(int, el.split('–'))\n",
    "                years.extend(list(range(start, end + 1)))\n",
    "            else:  # case of a single year within comma-separated years\n",
    "                years.append(int(el))\n",
    "    elif '–' in season:  # case of a range\n",
    "        season = re.sub(r'\\[.*\\]', '', season)  # strip off suffixes\n",
    "        start, end = map(int, season.split('–'))\n",
    "        years = list(range(start, end + 1))\n",
    "    else:  # case of a single year\n",
    "        season = re.sub(r'\\[.*\\]', '', season)  # strip off suffixes\n",
    "        years = [int(season)]\n",
    "    \n",
    "    return years\n",
    "\n",
    "# Apply function and create new column\n",
    "wiki_data['Year'] = wiki_data['Season(s)'].apply(split_years)\n",
    "\n",
    "# Expand the list of years into multiple rows\n",
    "wiki_data = wiki_data.explode('Year')\n",
    "\n",
    "# Convert 'Year' back to integer\n",
    "wiki_data['Year'] = wiki_data['Year'].astype(int)\n",
    "\n",
    "# Drop 'Season(s)' column\n",
    "wiki_data.drop(['Season(s)'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'Grands Prix' column at commas and create a list\n",
    "wiki_data['Grands Prix'] = wiki_data['Grands Prix'].str.split(',')\n",
    "wiki_data = wiki_data.explode('Grands Prix')\n",
    "wiki_data['Grands Prix'] = wiki_data['Grands Prix'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_cars['Year'] = safety_cars['Year'].astype(int)\n",
    "safety_cars['Race'] = safety_cars['Race'].str.lower()\n",
    "wiki_data['Grands Prix'] = wiki_data['Grands Prix'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge safety_cars and wiki_data into merge3\n",
    "merge3 = pd.merge(safety_cars, wiki_data, left_on=['Race', 'Year'], \n",
    "                  right_on=['Grands Prix', 'Year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns from races dataset and make race names lower case\n",
    "races.drop(columns=['url', 'fp1_date', 'fp1_time', 'fp2_date', 'fp2_time', 'fp3_date', \n",
    "                    'fp3_time', 'quali_date', 'quali_time', 'sprint_date', 'sprint_time', 'time'], inplace=True)\n",
    "races['name'] = races['name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge merge3 and races into merge4\n",
    "merge4 = pd.merge(merge3, races, left_on=['Race', 'Year'],\n",
    "                  right_on=['name', 'year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge merge2 and merge4 into merge5\n",
    "merge5 = pd.merge(merge2, merge4, left_on=['raceId'],\n",
    "                 right_on=['raceId',], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns from drivers dataset\n",
    "drivers.drop(columns=['url', 'dob'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge final and drivers\n",
    "final = pd.merge(merge5, drivers, left_on=['driverId'], right_on=['driverId'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename position column\n",
    "final.rename(columns={'position_x': 'position in lap'}, inplace=True)\n",
    "\n",
    "# Fill missing values for pit stops related columns\n",
    "final['stop'] = final['stop'].fillna('no pitstop')\n",
    "final['time_pit'] = final['time_pit'].fillna('no pitstop')\n",
    "final['duration'] = final['duration'].fillna('no pitstop')\n",
    "final['milliseconds_pit'] = final['milliseconds_pit'].fillna('no pitstop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export final df as final.csv to allow for the creation of the KG in knowledge_graph2.ipynb\n",
    "final.to_csv('final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_year_data(df, years):\n",
    "#     dataframes = []  # Initialize list to hold dataframes\n",
    "#     for year in years:\n",
    "#         # Filter data for specific year\n",
    "#         year_data = df[df['year'] == year]\n",
    "#         dataframes.append(year_data)  # Append the dataframe to the list\n",
    "\n",
    "#         # Save data to csv\n",
    "#         filename = f'f1_data_{year}.csv'\n",
    "#         year_data.to_csv(filename, index=False)\n",
    "        \n",
    "#     # Concatenate all the dataframes in the list\n",
    "#     all_data = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "#     return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_ = extract_year_data(final, [2018, 2019, 2020, 2021, 2022])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
